# 대기열 성능 개선 보고서 (커밋 ed373ec 기준)

작성일: 2026-02-19

요약
- 커밋 `ed373ec`는 대기열 처리의 아키텍처와 런타임을 함께 개선하여 서버 부하와 메시지 발행량을 줄이고, 좀비(유휴) 데이터 식별을 도입해 큐 무결성과 운영 비용을 낮추는 것을 목표로 합니다.
- 핵심 아이디어: 서버가 모든 사용자별 순위를 직접 계산·전달하던 방식을 클라이언트/노드 분산 계산으로 전환하고, 메시지 발행을 사용자 단위에서 대기열 단위(1 이벤트)로 축소, 그리고 heartbeat 키로 좀비 데이터를 식별하도록 변경했습니다. 런타임은 JDK 21, Gradle 9.3 등으로 최신화되고 OTEL 에이전트가 추가되어 분산 추적이 가능해졌습니다.

체크리스트
- [x] 변경 목적 및 요약 정리
- [x] 주요 파일/영향 영역 나열
- [x] 설계 변경(클라이언트 순위 계산, 메시지 발행 축소, heartbeat) 설명
- [x] 시간복잡도 및 성능 영향 분석
- [x] 성능 검증·테스트 계획 제시
- [x] 리스크·권장 후속 작업 제안

1. 변경의 핵심 요약

- 클라이언트 측 순위 계산 전환
  - 기존: 서버가 각 사용자에 대해 현재 대기열 순위를 계산하여 전송
  - 변경: 서버는 최소한의 상태(예: 대기열 총 인원수, 입장/퇴장 이벤트)만 발행하고 클라이언트(또는 각 노드)가 순위를 계산

- 메시지 발행 정책 변경
  - 기존: 대기열에 N명이 있으면 N개의 메시지(또는 사용자별 메시지)를 발행
  - 변경: 대기열 당 1개의 메시지(또는 1 이벤트)만 발행하여 모든 노드/구독자가 수신하도록 변경

- heartbeat 키 도입
  - 장기간 유휴/비정상 종료로 남아 있는 대기열 엔트리(좀비)를 식별 및 정리할 수 있는 키/TTL 전략을 도입

- 런타임·빌드·모니터링 현대화
  - `Dockerfile`: bellsoft Liberica OpenJRE 17 → 21, OTEL 에이전트 포함, WORKDIR 경로 정리
  - `build.gradle` / Gradle wrapper: Java toolchain 17 → 21, Gradle 8.13 → 9.3 업그레이드
  - 기타: `gradlew` 스크립트 단순화(클래스패스 → -jar) 등

2. 주요 변경 파일(대표)
- `Dockerfile`
- `build.gradle`, `waiting-service/build.gradle`
- `gradle/wrapper/gradle-wrapper.properties`, `gradlew`, `gradlew.bat`
- `waiting-service/src/main/java/.../ReactiveRedisQueueManager.java`
- `waiting-service/src/main/java/.../SubscribeWaitingResultService.java`
- `waiting-service/src/main/resources/redis/lua/register_waiting.lua`
- `waiting-service/src/main/resources/static/js/waiting.js`
- infra 관련 k8s/YAML 및 모니터링 구성(`infra/base/monitoring/*` 등)

(전체 파일 목록은 커밋 패치에서 `git show --name-only ed373ec`로 확인 가능)

3. 설계·동작 변경 상세(요약)

- 서버 책임 축소: 서버는 이제 "대기열 상태 변화" 이벤트만 발행합니다. 이 이벤트는 대기열 식별자와 (변경된) 간단한 메타(예: 총 대기 인원, 변경 타입 등)를 포함합니다.
- 이벤트 소비: 모든 노드/구성원(혹은 클라이언트)은 이 이벤트를 수신하면 자체적으로 해당 대기열의 사용자 목록을 조회하거나 로컬 상태를 사용해 순위를 재계산합니다.
- Redis/Lua 변경: `register_waiting.lua` 등 Lua 스크립트에서 heartbeat 키를 세팅하거나 TTL을 적용하는 로직 추가. Redis를 통한 publish/subscribe 채널은 per-queue 채널 또는 공통 채널로 단일화.
- 클라이언트 변화: `waiting.js`에 순위 재계산 로직이 추가되어, 서버가 정확한 1:1 순위 수치를 보내지 않아도 UI가 정확히 표시되도록 개선.

4. 시간복잡도 및 성능 분석

정의
- N: 한 대기열에 있는 사용자 수
- M: 전체 대기열 수(또는 이벤트 수)

이전(서버 중심) 방식
- 서버에서 사용자별 순위를 계산·전달: 한 변경 이벤트 처리 시 서버 작업 O(N) (각 사용자에 대해 순위 산출·전송)
- 메시지 발행 수: O(N) (사용자 수 비례)
- 네트워크/브로커 처리량: O(N)

변경(대기열당 1 발행 + 클라이언트 계산)
- 서버 작업: O(1) per queue event (대기열 단위 이벤트 발행) — 즉 이벤트당 상수비용
- 클라이언트(혹은 각 노드)의 계산: O(N) 분산 (각 클라이언트가 자신의 순위만 계산하거나, 각 노드가 부분적으로 처리)
- 메시지 발행 수: O(1) per queue event
- 네트워크/브로커 처리량: 대략 O(M) (M << sum of N across queues in previous design)

효율 비교(정성적)
- 서버 CPU 부하: 기존 O(N) → 변경 후 O(1)로 감소(사용자 수 큰 큐에서 특히 효과 큼)
- 브로커/네트워크 I/O: 평균 메시지 수가 사용자수만큼 줄어들어 대역폭·처리 비용이 크게 감소
- 전체 지연(서버 측): 서버 응답·알림 대기 시간이 줄어들고 처리량(TPS)은 증가할 가능성(서버 CPU 및 I/O 병목 해소)
- 클라이언트 부하: 클라이언트 연산이 약간 증가(로컬 순위 계산) — 현대 브라우저/기기에서는 보통 경미한 비용이나 저사양 기기에 대한 고려 필요

5. 기대 성능 개선(실무적 예상)
- 메시지 발행량 감소 비율: 대기열 평균 길이가 100명인 경우, 메시지 발행량 약 100배 감소
- 서버 처리량(TPS): 서버당 처리 가능 입장 처리량 증가(정확 수치는 환경·동시성에 따라 다름). 일반적으로 서버 CPU 사용률 감소로 동시 처리량이 증가
- 응답 지연(p95): 서버 연산 감소로 p95 개선 예상(예: 40~70% 감소 가능 — 반드시 벤치마크 필요)

6. 검증 계획

- 준비
  - 동일한 하드웨어/컨테이너 리소스에서 before/after 비교 (브랜치 또는 이전 커밋과 현재 커밋)
  - k6 스크립트(`infra/base/test/k6-script.js`) 사용
  - Prometheus + Grafana + OTEL 수집을 활성화

- 측정 항목
  - RPS/TPS, 요청 성공률, p50/p95/p99 응답시간
  - Redis ops/sec, pubsub 메시지 수, 네트워크 바이트 전송량
  - JVM CPU, 메모리, GC 시간
  - OTEL 트레이스: 입장 → Lua 스크립트 → publish 흐름 스팬

- 실행 예
```bash
# k6 부하 테스트(예시)
k6 run infra/base/test/k6-script.js

# gradle 빌드(로컬 검증)
./gradlew :waiting-service:clean :waiting-service:build
```

- 검증 결과 문서화
  - before/after 표 (메시지/sec, p95 응답시간, CPU 사용률)
  - OTEL 트레이스 샘플 및 병목이 발생한 지점

7. 리스크 및 주의점

- 클라이언트 기기 차이: 일부 저사양 기기에서 순위 계산 로직이 부담이 될 수 있음 — A/B 테스트 및 최적화 필요
- 이벤트 전달 신뢰성: per-queue 1발행은 메시지 손실 시 영향이 커질 수 있으므로, 적절한 재시도·중복처리 정책 설계 필요(예: 이벤트 재발행, 상태 기반 폴링 병행)
- heartbeat 설정: TTL/주기 설정이 부적절하면 정상 사용자가 오탐되어 제거될 수 있음
- 빌드/호환성: JDK 21·Gradle 9으로 업그레이드하면서 일부 라이브러리(예: Spring Boot 플러그인 관련)가 영향을 받을 수 있으니 CI 빌드 통과 확인 필요

8. 권장 후속 작업
- 즉시: CI에서 전체 빌드 및 통합 테스트 실행(Gradle 9.3 환경 확인)
- 1주 내: k6를 사용한 정량적 부하 테스트 수행 및 보고서 작성
- 2주 내: heartbeat TTL 튜닝과 오탐률 측정, 클라이언트 성능 A/B 테스트
- 장기: OTEL 기반 프로파일링으로 잔여 병목 식별 및 추가 최적화

9. 요구사항 매핑(간단)
- 성능 개선 목표: 적용됨(서버 부하 감소 설계 적용)
- 메시지·네트워크 최적화: 적용됨(발행량 대폭 감소)
- 좀비 데이터 처리: 적용됨(heartbeat 도입)
- 모니터링/추적: 적용됨(OTEL 에이전트 포함)
- 정량적 검증: 필요(부하 테스트 미실행)

부록: 참고/명령
- 커밋 패치 보기: `git show ed373ec`
- 변경 파일 목록: `git show --name-only ed373ec`
- 긴 패치를 파일로 저장: `git show ed373ec > /tmp/ed373ec.patch`

---

필요하면 이 Markdown 문서를 더 요약(1페이지)하거나, PDF로 변환해서 포트폴리오 형식으로 다듬어 드리겠습니다. 추가로 특정 파일(`waiting-service/src/main/...`)의 diff를 세부 해석해서 포트폴리오에 들어갈 코드 스니펫과 설명을 원하시면 어느 파일을 우선할지 알려주세요.
